options:
  logging: CLOUD_LOGGING_ONLY
 
steps:
  # Step 0: Build the Docker image from the Dockerfile
  - name: 'gcr.io/cloud-builders/docker'
    args: ['build', '-t', '$_REGION-docker.pkg.dev/$PROJECT_ID/$_REPOSITORY_NAME/$_IMAGE_NAME:latest', '.']
 
  # Step 1: Check if the Artifact Repository exists and create it if not
  - name: 'gcr.io/google.com/cloudsdktool/cloud-sdk'
    entrypoint: 'sh'
    args:
      - '-c'
      - |
        if ! gcloud artifacts repositories describe $_REPOSITORY_NAME --location=$_REGION --format='value(name)'; then
          echo "Repository $_REPOSITORY_NAME does not exist. Creating repository..."
          gcloud artifacts repositories create $_REPOSITORY_NAME --repository-format=docker --location=$_REGION
          echo "Repository $_REPOSITORY_NAME created."
        else
          echo "Repository $_REPOSITORY_NAME already exists."
        fi
 
  # Step 2: Push the image to Google Artifact Registry
  - name: 'gcr.io/cloud-builders/docker'
    args: ['push', '$_REGION-docker.pkg.dev/$PROJECT_ID/$_REPOSITORY_NAME/$_IMAGE_NAME:latest']
 
  # Step 3: Deploy the image to Google Cloud Run
  - name: 'gcr.io/google.com/cloudsdktool/cloud-sdk'
    entrypoint: 'gcloud'
    args:
      - 'run'
      - 'deploy'
      - '$_CLOUD_RUN_SERVICE'
      - '--image=$_REGION-docker.pkg.dev/$PROJECT_ID/$_REPOSITORY_NAME/$_IMAGE_NAME:latest'
      - '--region=$_REGION'
      - '--platform=managed'
      - '--memory=2Gi'
      - '--no-allow-unauthenticated'
      - '--ingress=internal'
      # IMPORTANTE: El paso de 'add-iam-policy-binding' con allUsers no tiene sentido con --no-allow-unauthenticated
      # Si el servicio es interno y no autenticado, solo será accesible desde la VPC.
      # Si es no autenticado pero no interno, entonces sí tendría sentido para acceso público.
      # Con --no-allow-unauthenticated, se requiere autenticación SIEMPRE.
      # Eliminar el siguiente paso si deseas que solo sea accesible por la red interna y autenticación.
      # Si necesitas que sea invocado por todos los usuarios PERO autenticados, este paso puede causar confusión.
      # Para servicios internos, los invocadores deben tener roles específicos y usar autenticación de cuenta de servicio.
 
  # ELIMINADO: Step 3.5: Otorgar permisos públicos al servicio de Cloud Run
  # ELIMINADO: Step 4: Add delay before checking status
  # ELIMINADO: Step 5: Check status and use the URL of the deployed Cloud Run service
 
  # Este es el nuevo paso para invocar el pipeline de Vertex AI DIRECTAMENTE desde Cloud Build
  - name: 'gcr.io/google.com/cloudsdktool/cloud-sdk'
    entrypoint: 'python3' # CAMBIO: Ejecutar directamente con python3
    args:
      - '-c'
      - |
        # Ya no es necesario activar la cuenta de servicio con un archivo JSON
        # porque la cuenta de servicio del trigger de Cloud Build ya está autenticada.
        # gcloud auth activate-service-account --key-file=/workspace/service-account-key.json # ELIMINADO
        gcloud config set project $PROJECT_ID
        gcloud config set compute/region $_REGION
 
        # Las dependencias de los componentes de Kubeflow/Vertex AI se instalan
        # dentro de las imágenes de los propios componentes. No es necesario
        # instalar requirements.txt en este paso del Cloud Build.
        # pip install -r requirements.txt # ELIMINADO
        # Ejecutar el script Python que compila y corre el pipeline de Vertex AI
        # Asegúrate de que tu script Python pueda encontrar 'config.json' y otros módulos
        # Por ejemplo, si run_pipeline está en pipeline/train_pipeline.py
        # El comando 'python' por sí solo puede apuntar a python2 en algunas imágenes,
        # 'python3' asegura la versión correcta.
        from pipeline.train_pipeline import compile_pipeline, run_pipeline
        compile_pipeline()
        run_pipeline()
 
substitutions:
  _PROJECT_ID: 'bdb-gcp-qa-cds-idt'
  _REGION: 'us-east4'
  _REPOSITORY_NAME: 'repo-mle-template'
  _IMAGE_NAME: 'mle-template'
  _CLOUD_RUN_SERVICE: 'mle-template-service'