options:
  logging: CLOUD_LOGGING_ONLY
 
steps:
  # Paso 0: Construir la imagen Docker desde el Dockerfile
  - name: 'gcr.io/cloud-builders/docker'
    args: ['build', '-t', '$_REGION-docker.pkg.dev/$PROJECT_ID/$_REPOSITORY_NAME/$_IMAGE_NAME:latest', '.']
    id: 'build-docker-image'
 
  # Paso 1: Verificar si el repositorio de Artifact Registry existe y crearlo si no
  - name: 'gcr.io/google.com/cloudsdktool/cloud-sdk'
    entrypoint: 'sh'
    args:
      - '-c'
      - |
        if ! gcloud artifacts repositories describe $_REPOSITORY_NAME --location=$_REGION --format='value(name)'; then
          echo "El repositorio $_REPOSITORY_NAME no existe. Creando repositorio..."
          gcloud artifacts repositories create $_REPOSITORY_NAME --repository-format=docker --location=$_REGION
          echo "Repositorio $_REPOSITORY_NAME creado."
        else
          echo "El repositorio $_REPOSITORY_NAME ya existe."
        fi
    id: 'check-create-repo'
 
  # Paso 2: Subir la imagen a Google Artifact Registry
  - name: 'gcr.io/cloud-builders/docker'
    args: ['push', '$_REGION-docker.pkg.dev/$PROJECT_ID/$_REPOSITORY_NAME/$_IMAGE_NAME:latest']
    id: 'push-docker-image'
 
  # Paso 3: Desplegar la imagen en Google Cloud Run (AHORA SÍ FUNCIONARÁ)
  - name: 'gcr.io/google.com/cloudsdktool/cloud-sdk'
    entrypoint: 'gcloud'
    args:
      - 'run'
      - 'deploy'
      - '$_CLOUD_RUN_SERVICE'
      - '--image=$_REGION-docker.pkg.dev/$PROJECT_ID/$_REPOSITORY_NAME/$_IMAGE_NAME:latest'
      - '--region=$_REGION'
      - '--platform=managed'
      - '--memory=2Gi'
      - '--no-allow-unauthenticated'
      - '--ingress=internal'
      # Puedes añadir --timeout si el arranque tarda mucho (ej: --timeout=60s)
    id: 'deploy-cloud-run'
 
  # Paso 4: Invocar el pipeline de Vertex AI utilizando TU PROPIA IMAGEN Docker
  # Aquí ANULAMOS el CMD por defecto de Gunicorn para ejecutar tu script Python.
  - name: '$_REGION-docker.pkg.dev/$PROJECT_ID/$_REPOSITORY_NAME/$_IMAGE_NAME:latest'
    entrypoint: 'python3' # El entrypoint para ejecutar el script
    args:
      - 'pipeline/train_pipeline.py' # Ejecuta directamente el script
    id: 'run-vertex-pipeline'
 
substitutions:
  _PROJECT_ID: 'bdb-gcp-qa-cds-idt'
  _REGION: 'us-east4'
  _REPOSITORY_NAME: 'repo-mle-template'
  _IMAGE_NAME: 'mle-template'
  _CLOUD_RUN_SERVICE: 'mle-template-service'